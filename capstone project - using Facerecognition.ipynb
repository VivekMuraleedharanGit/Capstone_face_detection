{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "#from deepface import DeepFacerecon \n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=[]\n",
    "face_known_encodings=[]\n",
    "face_known_name = []\n",
    "pred_names = []\n",
    "face_known_encodings_flat=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video2encoding(vid_source,names):\n",
    "    cam = cv2.VideoCapture(vid_source)\n",
    "    currentframe = 0\n",
    "    frame_no = 0\n",
    "    know_encodings = []\n",
    "    #os.chdir(path)\n",
    "\n",
    "    while True: \n",
    "\n",
    "        # reading from frame \n",
    "        ret,frame = cam.read()\n",
    "        #print(ret)\n",
    "        if ret==True:\n",
    "            #print (frame_no)\n",
    "            if frame_no%6 == 1:\n",
    "                #img = face_recognition.load_image_file(frame)\n",
    "                face_locations = face_recognition.face_locations(frame)\n",
    "                if len(face_locations)!= 0:\n",
    "                    face_encoding = face_recognition.face_encodings(frame,known_face_locations=face_locations)\n",
    "                    #image_face = DeepFace.detectFace(RGB)\n",
    "                    know_encodings.append(face_encoding)\n",
    "                for face_locations in face_locations:\n",
    "                    cv2.rectangle(frame,(face_locations[3],face_locations[0]), (face_locations[1],face_locations[2]), (255, 0, 0), 2)\n",
    "                    #print(face_locations)\n",
    "                    #cv2.imshow(\"video\",frame)\n",
    "                    #cv2.waitKey(1)\n",
    "                #face_encoding = face_recognition.face_encodings(frame,known_face_locations=face_locations)[0]\n",
    "                #know_encodings.append(face_encoding)\n",
    "                #print(know_encodings)\n",
    "                #print ('Creating...' + name)\n",
    "                #cv2.imwrite(name, cv2.cvtColor(image_face*255,cv2.COLOR_BGR2RGB))\n",
    "                #cv2.imwrite(name,frame)\n",
    "            frame_no = frame_no+1\n",
    "\n",
    "            currentframe += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Release all space and windows once done \n",
    "    cam.release() \n",
    "    cv2.destroyAllWindows() \n",
    "    faces.append([names,know_encodings])\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video2encoding(\"C:\\\\Users\\\\ethic\\\\Pictures\\\\Camera Roll\\\\WIN_20201028_23_37_10_Pro.mp4\",\"Darshan\")\n",
    "video2encoding(\"D:\\\\Downloads\\\\Vivek_video.mp4\",\"Vivek\")\n",
    "#video2encoding(\"D:\\\\Downloads\\\\VID_20201028_212451_01.mp4\",\"harish\")\n",
    "video2encoding(\"D:\\\\Downloads\\\\Satish_Video.mp4\",\"Sathish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,len(faces)):\n",
    "    for i in range(0,len(faces[j][1])):\n",
    "        face_known_encodings.append(faces[j][1][i])\n",
    "#a=list(itertools.chain(*face_known_encodings))\n",
    "for x in face_known_encodings:\n",
    "    for y in x:\n",
    "        face_known_encodings_flat.append(y)\n",
    "for j in range(0,len(faces)):\n",
    "    for i in range(0,len(faces[j][1])):\n",
    "        face_known_name.append(faces[j][0])\n",
    "#face_known_encodings = [y for x in face_known_encodings for y in x]\n",
    "#reduce(lambda x, y: x.extend(y),face_known_encodings)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(face_known_name))\n",
    "print(len(face_known_encodings_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "try:\n",
    "    while True:\n",
    "        \n",
    "        # Read the frame\n",
    "        _, img = cap.read()\n",
    "        #print(_)\n",
    "        # Convert to RGB\n",
    "        #half = cv2.resize(img, (0, 0),fx=0.2,fy=0.2) \n",
    "        #RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect the faces\n",
    "\n",
    "        face_locations = face_recognition.face_locations(img)\n",
    "        if len(face_locations)!= 0:\n",
    "            #face_encoding = face_recognition.face_encodings(frame,known_face_locations=face_locations)\n",
    "            face_encoding = face_recognition.face_encodings(img,known_face_locations=face_locations)[0] \n",
    "            #print(face_encoding)\n",
    "        #Draw the rectangle around each face\n",
    "        for face_locations in face_locations:\n",
    "            cv2.rectangle(img,(face_locations[3],face_locations[0]), (face_locations[1],face_locations[2]), (255, 0, 0), 2)\n",
    "\n",
    "            face_recognize = face_recognition.face_distance(face_known_encodings_flat,face_encoding)\n",
    "            face_recognize_test = face_recognize < 0.6\n",
    "            true= sum(face_recognize_test)\n",
    "            false = len(face_recognize_test)-true\n",
    "            #print(true)\n",
    "            #print(false)\n",
    "            #print(face_recognize_test)\n",
    "            #print(face_recognize)\n",
    "            if true >= 30:\n",
    "                #print(len(face_recognize))\n",
    "                #print(np.argmin(face_recognize))\n",
    "                #print(min(face_recognize))\n",
    "                best_match_index = np.argmin(face_recognize)\n",
    "                pred_names.append(face_known_name[best_match_index])\n",
    "                if len(pred_names) == 15:\n",
    "                    name = stats.mode(pred_names)\n",
    "                    print(name.mode)\n",
    "                    pred_names = []\n",
    "        #break\n",
    "            elif true < 30:\n",
    "                print(\"unknown face\")\n",
    "        # Display\n",
    "\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"done!\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
