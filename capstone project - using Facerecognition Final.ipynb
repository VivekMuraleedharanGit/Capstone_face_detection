{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install all dependencies before running this code\n",
    "#### pip install opencv-python\n",
    "#### pip install Cmake\n",
    "#### pip install Dlib\n",
    "#### pip install face-recognition\n",
    "#### pip install itertools-s\n",
    "#### pip install pyttsx3\n",
    "#### Install visual studio 2019 community version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import pyttsx3\n",
    "import threading\n",
    "import pyodbc\n",
    "from tkinter import *\n",
    "import sys\n",
    "from PIL import ImageTk,Image\n",
    "from datetime import datetime\n",
    "import time\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_known_encodings=[]\n",
    "face_known_name = []\n",
    "pred_names = []\n",
    "face_known_encodings_flat=[]\n",
    "engine = pyttsx3.init()\n",
    "cam = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video to encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will open your webcam and captures your encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video2encoding(vid_source,names):\n",
    "    global faces\n",
    "    global panel\n",
    "    faces=[]\n",
    "    cam = cv2.VideoCapture(vid_source)\n",
    "    frame_no = 0\n",
    "    know_encodings = []\n",
    "    root.update()\n",
    "    while True: \n",
    "\n",
    "        # reading from frame \n",
    "        ret,frame = cam.read()\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        image = ImageTk.PhotoImage(image)\n",
    "        panel = Label(image=image)\n",
    "        panel.image = image\n",
    "        panel.place(x=300, y=270)\n",
    "        if len(know_encodings) == 45:\n",
    "            break\n",
    "        #print(ret)\n",
    "        if ret==True:\n",
    "            #print (frame_no)\n",
    "            face_locations = face_recognition.face_locations(frame)\n",
    "            if len(face_locations)!= 0:\n",
    "                face_encoding = face_recognition.face_encodings(frame,known_face_locations=face_locations)\n",
    "                know_encodings.append(face_encoding)\n",
    "            for face_locations in face_locations:\n",
    "                cv2.rectangle(frame,(face_locations[3],face_locations[0]), (face_locations[1],face_locations[2]), (255, 0, 0), 2)     \n",
    "            frame_no = frame_no+1\n",
    "            #cv2.imshow('img', frame)\n",
    "            cv2.waitKey(1)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Release all space and windows once done\n",
    "    \n",
    "    cam.release() \n",
    "    cv2.destroyAllWindows() \n",
    "    faces.append([names,know_encodings])\n",
    "    print(\"done\")\n",
    "    export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for exporting new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will save the encodings in new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame()\n",
    "def encoding_df (faces):\n",
    "   \n",
    "    for j in range(0,len(faces)):\n",
    "        test = faces[j][1]\n",
    "        name = faces[j][0]\n",
    "        #print(name)\n",
    "        a=list(itertools.chain(*test))\n",
    "        b=list(itertools.chain(*a))\n",
    "        df[[name]]=pd.DataFrame(b)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a new face to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will open the existing dataframe and adds new encodings into a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"C:\\\\Users\\\\CTS\\\\Desktop\\Capstone\\\\encoding.csv\"\n",
    "def add_new_encoding(source,faces,eid):\n",
    "    df=pd.read_csv(source)\n",
    "    for j in range(0,len(faces)):\n",
    "        test = faces[j][1]\n",
    "        name = faces[j][0]\n",
    "        #print(name)\n",
    "        a=list(itertools.chain(*test))\n",
    "        b=list(itertools.chain(*a))\n",
    "        #print(b)\n",
    "        df[[eid]]=pd.DataFrame(b)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data to required format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converts the csv into a format that the model can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2encodings(data): \n",
    "    names=data.columns.values\n",
    "    lengths=[]\n",
    "    encodings=[]\n",
    "    known_encodings=[]\n",
    "    known_names=[]\n",
    "    for i in names:\n",
    "        data_1=data[i]\n",
    "        data_1 = data_1.dropna()\n",
    "        data_2=data_1.to_list()\n",
    "        encodings.append(data_2)\n",
    "        lengths.append(len(data_2)/128)\n",
    "\n",
    "    for j in range(0,len(encodings)):\n",
    "        for i in range(0,round(len(encodings[j])/128) ):\n",
    "            x=0\n",
    "            y=128\n",
    "            known_encodings.append(np.array(encodings[j][x:y]))\n",
    "            x = (x+128)+1\n",
    "            y= y+128#\n",
    "\n",
    "    for i in range(0,len(lengths)):\n",
    "        for j in range(0,round(lengths[i])):\n",
    "            known_names.append(names[i])\n",
    "    #print(lengths)\n",
    "    #print(names)\n",
    "    return(known_names,known_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed to 2 functions - FOR FRONT END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compares the encodings in the csv with current encodings from the camera and detects the person in the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    empn=''\n",
    "    pred_names=[]\n",
    "    data = pd.read_csv(\"C:\\\\Users\\\\CTS\\\\Desktop\\Capstone\\\\encoding.csv\")\n",
    "    face_known_name,face_known_encodings_flat=csv2encodings(data)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    name = \"\"\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "\n",
    "            # Read the frame\n",
    "            _, img = cap.read()\n",
    "\n",
    "            # Detect the faces\n",
    "\n",
    "            face_locations = face_recognition.face_locations(img)\n",
    "            if len(face_locations)!= 0:\n",
    "                face_encoding = face_recognition.face_encodings(img,known_face_locations=face_locations)[0] \n",
    "\n",
    "            else:\n",
    "                pred_names = []\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(img,\"finding new face\",(25,25) ,font, 1.0, (255, 0, 0), 1)\n",
    "\n",
    "            #Draw the rectangle around each face\n",
    "\n",
    "            for face_locations in face_locations:\n",
    "                cv2.rectangle(img,(face_locations[3],face_locations[0]), (face_locations[1],face_locations[2]), (255, 0, 0), 2)\n",
    "\n",
    "                face_recognize = face_recognition.face_distance(face_known_encodings_flat,face_encoding)\n",
    "                face_recognize_test = face_recognize < 0.6\n",
    "                true= sum(face_recognize_test)\n",
    "                if true >= 30:\n",
    "                    best_match_index = np.argmin(face_recognize)\n",
    "                    pred_names.append(face_known_name[best_match_index])\n",
    "                    if len(pred_names) == 5:\n",
    "                        name = stats.mode(pred_names)\n",
    "                        name = name.mode.item()\n",
    "                        conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                            'Server=VIVEKSSURFACE;'\n",
    "                          'Database=empDB;'\n",
    "                          'Trusted_Connection=yes;')\n",
    "                        empn=pd.read_sql_query(\"select empname from empinfo where empid='%s'\"% name,conn)\n",
    "                        print(empn)\n",
    "                        empn=empn.values.item()\n",
    "                        now =datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "                        #print(empn)\n",
    "                        #print(name)\n",
    "                        #print(now)\n",
    "                        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                        cv2.putText(img,empn, (face_locations[3] + 6, face_locations[2]- 6), font, 0.5, (255, 255, 255), 1)\n",
    "                        engine.say(\"Good morning,\"+empn)\n",
    "                        engine.say(\"Have a great day!\")\n",
    "                        #engine.runAndWait()\n",
    "                        engine.stop()\n",
    "                        cnx=pyodbc.connect('Driver={SQL Server};'\n",
    "                            'Server=VIVEKSSURFACE;'\n",
    "                            'Database=empDB;'\n",
    "                            'Trusted_Connection=yes;')\n",
    "                        cuo=cnx.cursor()\n",
    "                        SQLCommand=('INSERT INTO attendance_log (empid,empname,punchtime) VALUES (?,?,?)')\n",
    "                        Values = [name,empn,now]\n",
    "                        cuo.execute(SQLCommand,Values)  \n",
    "                        cnx.commit()\n",
    "                        pred_names = []\n",
    "\n",
    "                else:\n",
    "                    name = \"unknown face\"\n",
    "                    engine.say(\"Sorry !\")\n",
    "                    engine.say(\"Not able to identify who you are\")\n",
    "                    #engine.runAndWait()\n",
    "                    engine.stop()\n",
    "\n",
    "            # Display\n",
    "                if empn == \"\":\n",
    "                    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                    cv2.putText(img,\"identifying ....\", (face_locations[3] + 6, face_locations[2]- 6), font, 0.5, (255, 255, 255), 1)\n",
    "                else:\n",
    "                    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                    cv2.putText(img,empn, (face_locations[3] + 6, face_locations[2]- 6), font, 0.5, (255, 255, 255), 1)\n",
    "                    empn=''\n",
    "                    time.sleep(5)\n",
    "            cv2.imshow('img', img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"done!\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    empn=''\n",
    "    pred_names=[]\n",
    "    data = pd.read_csv(\"C:\\\\Users\\\\CTS\\\\Desktop\\Capstone\\\\encoding.csv\")\n",
    "    face_known_name,face_known_encodings_flat=csv2encodings(data)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_EXPOSURE,-1)\n",
    "    name = \"\"\n",
    "    model = tf.keras.models.load_model('C:\\\\Users\\\\CTS\\\\Desktop\\\\Capstone\\\\rps1.h5',custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "    \n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "\n",
    "            # Read the frame\n",
    "            _, img = cap.read()\n",
    "            # Detect the faces\n",
    "            face_locations = face_recognition.face_locations(img)\n",
    "            imgs = cv2.resize(img,(224,224))\n",
    "            x = image.img_to_array(imgs/255)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            images = np.vstack([x])\n",
    "            classes = np.round(model.predict(images, batch_size=10))\n",
    "            if len(face_locations)!= 0:\n",
    "                face_encoding = face_recognition.face_encodings(img,known_face_locations=face_locations)[0] \n",
    "\n",
    "            else:\n",
    "                pred_names = []\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(img,\"finding new face\",(25,25) ,font, 1.0, (255, 0, 0), 1)\n",
    "            #Draw the rectangle around each face\n",
    "            for face_locations in face_locations:\n",
    "                cv2.rectangle(img,(face_locations[3],face_locations[0]), (face_locations[1],face_locations[2]), (255, 0, 0), 2)\n",
    "                if classes[0][1] == 1:\n",
    "                    pred_names = []\n",
    "                    break\n",
    "                if empn == \"\":\n",
    "                    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                    cv2.putText(img,\"identifying ....\", (face_locations[3] + 6, face_locations[2]- 6), font, 0.5, (255, 255, 255), 1)\n",
    "                else:\n",
    "                    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                    cv2.putText(img,empn, (face_locations[3] + 6, face_locations[2]- 6), font, 0.5, (255, 255, 255), 1)\n",
    "                    empn=''\n",
    "                face_recognize = face_recognition.face_distance(face_known_encodings_flat,face_encoding)\n",
    "                face_recognize_test = face_recognize < 0.6\n",
    "                true= sum(face_recognize_test)\n",
    "                if true >= 30:\n",
    "                    best_match_index = np.argmin(face_recognize)\n",
    "                    pred_names.append(face_known_name[best_match_index])\n",
    "                    if len(pred_names) == 5:\n",
    "                        name = stats.mode(pred_names)\n",
    "                        name = name.mode.item()\n",
    "                        conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                            'Server=VIVEKSSURFACE;'\n",
    "                          'Database=empDB;'\n",
    "                          'Trusted_Connection=yes;')\n",
    "                        empn=pd.read_sql_query(\"select empname from empinfo where empid='%s'\"% name,conn)\n",
    "                        empn=empn.values.item()\n",
    "                        now =datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "                        #print(empn)\n",
    "                        #print(name)\n",
    "                        #print(now)\n",
    "                        #engine.say(\"Good morning,\"+empn)\n",
    "                        #engine.say(\"Have a great day!\")\n",
    "                        #engine.runAndWait()\n",
    "                        #engine.stop()\n",
    "                        cnx=pyodbc.connect('Driver={SQL Server};'\n",
    "                            'Server=VIVEKSSURFACE;'\n",
    "                            'Database=empDB;'\n",
    "                            'Trusted_Connection=yes;')\n",
    "                        cuo=cnx.cursor()\n",
    "                        SQLCommand=('INSERT INTO attendance_log (empid,empname,punchtime) VALUES (?,?,?)')\n",
    "                        Values = [name,empn,now]\n",
    "                        cuo.execute(SQLCommand,Values)  \n",
    "                        cnx.commit()\n",
    "                        pred_names = []\n",
    "\n",
    "                else:\n",
    "                    name = \"unknown face\"\n",
    "                    #engine.say(\"Sorry !\")\n",
    "                    #engine.say(\"Not able to identify who you are\")\n",
    "                    #engine.runAndWait()\n",
    "                    #engine.stop()\n",
    "\n",
    "            # Display\n",
    "                \n",
    "                    #time.sleep(5)\n",
    "            cv2.imshow('img', img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"done!\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispalys the video frames into Tkinter and also records new encodings in BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn(video_src,ids,csv_source):\n",
    "    global emp\n",
    "    conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=VIVEKSSURFACE;'\n",
    "                      'Database=empDB;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "    emp=pd.read_sql_query(\"select empname from empinfo where empid='%s'\"% ids,conn)\n",
    "    emp=emp.values.item()\n",
    "    thread = threading.Thread(target=video2encoding, args=(0,eid))\n",
    "    thread.start()\n",
    "    cam.release() \n",
    "    root.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function calls add_new_encoding where encodings are saved in df and then it exports it into csv here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export():\n",
    "    csv_source=\"C:\\\\Users\\\\CTS\\\\Desktop\\Capstone\\\\encoding.csv\"\n",
    "    data_new = add_new_encoding(csv_source,faces,eid)\n",
    "    os.chdir(\"C:\\\\Users\\\\CTS\\\\Desktop\\Capstone\")\n",
    "    data_new.to_csv(\"encoding.csv\",header=True,index=False)\n",
    "    cnxn=pyodbc.connect('Driver={SQL Server};'\n",
    "                                        'Server=VIVEKSSURFACE;'\n",
    "                                        'Database=empDB;'\n",
    "                                        'Trusted_Connection=yes;')\n",
    "    cur=cnxn.cursor()\n",
    "    SQLCommand=(\"update empinfo set videocapture=1,vcapdt=GETDATE() where empid='%s'\"% eid)\n",
    "    cur.execute(SQLCommand)  \n",
    "    cnxn.commit()\n",
    "    return(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRONT END (UI) - TKINTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function contains the labels to be displayed in tkinter with its coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_url():\n",
    "    global eid\n",
    "    global url_entry\n",
    "    eid=url_entry.get()\n",
    "    cnxn=pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=VIVEKSSURFACE;'\n",
    "                      'Database=empDB;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "    cursor=cnxn.cursor()\n",
    "    val=pd.read_sql_query(\"select empname,dob,gender,dept from empinfo where empid='%s'\"% eid,cnxn)\n",
    "    val=val.values\n",
    "    ename=val[0][0]\n",
    "    dob=val[0][1]\n",
    "    gender=val[0][2]\n",
    "    dept=val[0][3]\n",
    "    head=['NAME:','DOB:','GENDER:','DEPARTMENT NAME:']\n",
    "    enamel=StringVar()\n",
    "    enamel.set(head[0])\n",
    "    label1=Label(root,textvariable=enamel,justify=LEFT,font=('Helvetica', 11, 'bold'))\n",
    "    label1.place(x =40,y =180)\n",
    "    enamep=StringVar()\n",
    "    enamep.set(ename.upper())\n",
    "    label5=Label(root,textvariable=enamep,justify=LEFT,font=('Helvetica', 11),bg=\"white\")\n",
    "    label5.place(x =40,y =205)\n",
    "    \n",
    "    dobl=StringVar()\n",
    "    dobl.set(head[1])\n",
    "    label2=Label(root,textvariable=dobl,justify=LEFT,font=('Helvetica', 11, 'bold'))\n",
    "    label2.place(x =40,y =240)\n",
    "    dobp=StringVar()\n",
    "    dobp.set(dob)\n",
    "    label6=Label(root,textvariable=dobp,justify=LEFT,font=('Helvetica', 11),bg=\"white\")\n",
    "    label6.place(x =40,y =265)\n",
    "    \n",
    "    genderl=StringVar()\n",
    "    genderl.set(head[2])\n",
    "    label3=Label(root,textvariable=genderl,justify=LEFT,font=('Helvetica', 11, 'bold'))\n",
    "    label3.place(x =40,y =300)\n",
    "    genderp=StringVar()\n",
    "    genderp.set(gender.upper())\n",
    "    label7=Label(root,textvariable=genderp,justify=LEFT,font=('Helvetica', 11),bg=\"white\")\n",
    "    label7.place(x =40,y =325)\n",
    "    \n",
    "    deptl=StringVar()\n",
    "    deptl.set(head[3])\n",
    "    label4=Label(root,textvariable=deptl,justify=LEFT,font=('Helvetica', 11, 'bold'))\n",
    "    label4.place(x =40,y =360)\n",
    "    deptp=StringVar()\n",
    "    deptp.set(dept.upper())\n",
    "    label8=Label(root,textvariable=deptp,justify=LEFT,font=('Helvetica', 11),bg=\"white\")\n",
    "    label8.place(x =40,y =385)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function is called when CAPTURE button is clicked, which intiates the video encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lena():\n",
    "    learn(0,eid,\"C:\\\\Users\\\\CTS\\\\Desktop\\Capstone\\\\encoding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "root =Tk()\n",
    "var=StringVar()\n",
    "label=Label(root,textvariable=var,font='Arial')\n",
    "label.place(x =100,y =20)\n",
    "#iurl=Button(root,text='SEARCH',font=('Helvetica', 14, 'bold'),compound = LEFT)\n",
    "#iaddurl = PhotoImage(file =\"C:\\\\Users\\\\harish\\\\Desktop\\\\Button\\\\final\\\\url.png\")\n",
    "#iurl= iaddurl.subsample(4,4)\n",
    "root.geometry('1000x800')\n",
    "label0=Label(root,text='EMPLOYEE ID',justify=LEFT,font=('Helvetica', 11, 'bold'))\n",
    "label0.place(x =40,y =100)\n",
    "url_entry = Entry(root,width = 25,borderwidth =7)\n",
    "button_add = Button(root,text='SEARCH',font=('Helvetica', 14, 'bold'),compound = LEFT,command = add_url)\n",
    "url_entry.place(x=40,y=130)\n",
    "button_add.place(x=215,y=120)\n",
    "capt = Button(root,text='CAPTURE',font=('Helvetica', 15, 'bold'),compound = LEFT,command=lena)\n",
    "capt.place(x=160,y=500)\n",
    "root.bind('<Escape>', lambda e: root.quit())\n",
    "lmain = Label(root)\n",
    "lmain.place(x=100,y=200)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
